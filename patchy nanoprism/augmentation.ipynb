{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data augmentation\n",
    "#Written by Lehan Yao from Qian Chen Group, MatSE, UIUC\n",
    "#Sept. 21, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelPath = 'manual label'\n",
    "nameList = [os.path.basename(x) for x in glob.glob(labelPath+'/image/*.tif')]\n",
    "stack = np.zeros([len(nameList),512,512,3]) #container for storing the labels and images\n",
    "\n",
    "i = 0\n",
    "for name in nameList: #read the labels and images and store them in RGB channels\n",
    "    I_image = cv2.imread(labelPath + '/image/' + name )\n",
    "    I_particle = cv2.imread(labelPath + '/mask/' + name )[:,:,2]\n",
    "    I_polymer = cv2.imread(labelPath + '/mask/' + name )[:,:,1]\n",
    "    stack[i,:,:,0] = cv2.cvtColor(I_image, cv2.COLOR_BGR2GRAY)\n",
    "    stack[i,:,:,1] = I_particle\n",
    "    stack[i,:,:,2] = I_polymer\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "volume = 1200 #the number of images in the augmented dataset\n",
    "data_gen_args_train = dict(fill_mode = 'reflect', rotation_range=360, zoom_range=0.1, horizontal_flip = True, vertical_flip = True, brightness_range = (0.8,1.2))\n",
    "datagen_train = ImageDataGenerator(**data_gen_args_train)\n",
    "seed = 1\n",
    "image_generator_train = datagen_train.flow(stack ,seed = seed) #RGB channels thus labels and images will be transformed together\n",
    "i = 0\n",
    "no = 0\n",
    "while (no < volume):\n",
    "    im = next(image_generator_train)\n",
    "    for j in range(im.shape[0]):\n",
    "        t = im[j,:,:,0]\n",
    "        m1 = im[j,:,:,1] > 128\n",
    "        m2 = im[j,:,:,2] > 128\n",
    "        m3 = np.logical_not(np.logical_or(m1,m2)) #m3 is the background class\n",
    "        m = np.stack([m1,m2,m3],2)\n",
    "        t = np.uint8(t)\n",
    "        m = np.uint8(m)*255\n",
    "        cv2.imwrite('train/'+str(no)+'.tif', t)\n",
    "        cv2.imwrite('label/'+str(no)+'.tif', m)\n",
    "        no += 1\n",
    "        if not no < volume:\n",
    "            break\n",
    "    i += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
